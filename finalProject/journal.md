# Robota Psyche Final Project Journal 

### April 26, 2021

For academic sources, I have narrowed down my pool to two academic papers that argue the plausibility of General AI (https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.47.9108&rep=rep1&type=pdf takes an optimistic approach towards the development of general AI from a technical standpoint, whereas  https://www.nature.com/articles/s41599-020-0494-4.pdf uses a combination of technical and philosophical arguments to assert that general AI may not even be possible at all). In addition, some other non-academic sources will include the whitepapers published by Neuralink and Deepmind.

In addition, I will also be exploring what general AI would mean in terms of the existing inequalities in our society. Last semester, I took a course called Thinking, Learning and Consciousness in Humans and Machines taught by Prof. David Stasavage from NYU New York - it was basically a set of 12 lectures - delivered by 12 diff professors from 12 diff disciplines discussing the impact of AI in their fields of study (including art, social sciences, physical sciences, law, and so on). One of these lectures was delivered by Prof. Meredith Broussard, who is a Professor of Journalism at NYU in New York. Her book, Artificial Unintelligence, is one of the most well-known works arguing for lesser AI in decision-making because of the dangers it may pose towards exacerbating social inequalities. I intend to specific parts of her book as a source (including some parts I don't agree with) to try and create a well-rounded image of where potential avenues for unintended social damage due to general AI may lie.

#### *To sum up in one line, my subject can be boiled down to: "Can general AI be developed - and if yes, should we develop it?"*
