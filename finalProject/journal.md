# Robota Psyche Final Project Journal 

### April 26, 2021

For academic sources, I have narrowed down my pool to two academic papers that argue the plausibility of General AI ([this article](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.47.9108&rep=rep1&type=pdf) takes an optimistic approach towards the development of general AI from a technical standpoint, whereas [this one](https://www.nature.com/articles/s41599-020-0494-4.pdf) uses a combination of technical and philosophical arguments to assert that general AI may not even be possible at all). In addition, some other non-academic sources will include the whitepapers published by Neuralink and Deepmind.

In addition, I will also be exploring what general AI would mean in terms of the existing inequalities in our society. Last semester, I took a course called Thinking, Learning and Consciousness in Humans and Machines taught by Prof. David Stasavage from NYU New York - it was basically a set of 12 lectures - delivered by 12 diff professors from 12 diff disciplines discussing the impact of AI in their fields of study (including art, social sciences, physical sciences, law, and so on). One of these lectures was delivered by Prof. Meredith Broussard, who is a Professor of Journalism at NYU in New York. Her book, Artificial Unintelligence, is one of the most well-known works arguing for lesser AI in decision-making because of the dangers it may pose towards exacerbating social inequalities. I intend to specific parts of her book as a source (including some parts I don't agree with) to try and create a well-rounded image of where potential avenues for unintended social damage due to general AI may lie.

#### *To sum up in one line, my subject can be boiled down to: "Can general AI be developed - and if yes, should we develop it?"*

### April 30 2021

I have not been able to give much time to this project so far - but I have made some more progress with narrowing down my sources. This includes a research paper from [DeepMind researchers about definiing universal intelligence](https://www.nature.com/articles/s41599-020-0494-4) as well as an article from the [IBM Archives](https://www.ibm.com/ibm/history/exhibits/valueone/valueone_bad.html) that seeks to portray their side of the story for the ALERT system which was a victim of systemic racial bias in the data sets fed to it.

### May 7 2021

Due to the situation back home as well as the impending final exams, it has been very difficult to focus on this task at hand. I made some progress with the paper today, including fleshing out the section where I detail the existing challenges towards the development of Artificial General Intelligence (AGI). In addition, I have begun forming my arguments for the ethical and equity-driven side of the debate.

### May 9 2021

Just finished the project in a long productive session - this included writing out an introduction which accurately reflects the industry's split opinion on the plausibility of AGI, a segue into the biological reasons why AGI won't be possible in the short term due to our limited understanding of the brain, and the strong condition required to categorize a system as a true AGI - which is - the ability to self-learn at superhuman speeds across domains, without the need for extensive repurposing. This may be a tall order but without fulfilling this, it seems quite difficult to expand the frontiers of narrow domain-bound finite games into open domain general intelligence.
