# Discussion Questions inspired by 'Robbie' and 'Runaround' - Isaac Asimov

## 1. Is a restrictive approach to programming robotic behavior the best possible method?
Asimov's Laws are based on the idea of restricting the operating outcomes of a robot's behavior. This is seen in the language - must, must not, and so on. Most of Asimov's stories are themselves based around the inadequacy of his own laws - what kind of approach would work best in real life?
## 2. Hacking psychology and the underlying biology
The way we react to situations is often governed by chemical activity in our brain. Serotonin, for instance, stabilizes our mood and promotes feelings of well-being/ happiness. Cortisol on the other hand has an opposite stress-inducing effect. When recreating a reflection of human intelligence within robots, is there a need for us to replicate our emotional frameworks or is the ability to simply process them is enough for a robot? Put another way, is it enough for Alexa in 2050 to be able to distinguish your moods (alongwith being sentient, aware of its existence, and artificially intelligent), or would you want it to go through mood swings as well (where it could be sad or happy based on external stimuli)? What about robots' mental health if your answer to the previous question is yes?
## 3. 
## 4. Technology has a unique way of solving problems: death.
When Steve Jobs mentioned the problem of not enough people knowing how to type as a hinderance towards the mass adoption of personal computing devices, he famously quipped that "We realised that eventually, death will take care of this problem for us." 

Could a similar pattern emerge with the subject of robots and their status as equal beings - where perhaps a world where children like Susan grow up to be decision makers would automatically gravitate towards affording robots equal rights, and death will take care of our present worldview where we remain keen to draw a line?
## 5. Concerns about an uprising
How realistic is the idea that sentient AI can be specialized to the same extent as hardware? For instance, a watch cannot suddenly change into a smartphone, and similarly Robbie is programmed to be a nursemaid and some behaviors are therefore hard-coded into it's brain. Are fears of an AI uprising then exaggerated, given that specialized AI, even if sentient, could be limited to certain behavioral patterns that are conducive to it's job description?


